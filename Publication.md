---
layout: page
title: My Publications
---
<p style="text-align: center;"> This section includes my research, ordered from newest to oldest. </p>

#### 1. VoluMe -- Authentic 3D Video Calls from Live Gaussian Splat Prediction. [`arXiv`](https://arxiv.org/abs/2507.21311)

Martin de La Gorce, Charlie Hewitt, Tibor Takacs, Robert Gerdisch, <span style="color:blue"> ***Zafiirah Hosenie***</span>, Givi Meishvili, Marek Kowalski, Thomas J. Cashman, Antonio Criminisi
<p align="justify">Virtual 3D meetings offer the potential to enhance copresence, increase engagement and thus improve effectiveness of remote meetings compared to standard 2D video calls. However, representing people in 3D meetings remains a challenge; existing solutions achieve high quality by using complex hardware, making use of fixed appearance via enrolment, or by inverting a pre-trained generative model. These approaches lead to constraints that are unwelcome and ill-fitting for videoconferencing applications. We present the first method to predict 3D Gaussian reconstructions in real time from a single 2D webcam feed, where the 3D representation is not only live and realistic, but also authentic to the input video. By conditioning the 3D representation on each video frame independently, our reconstruction faithfully recreates the input video from the captured viewpoint (a property we call authenticity), while generalizing realistically to novel viewpoints. Additionally, we introduce a stability loss to obtain reconstructions that are temporally stable on video sequences. We show that our method delivers state-of-the-art accuracy in visual quality and stability metrics compared to existing methods, and demonstrate our approach in live one-to-one 3D meetings using only a standard 2D camera and display. This demonstrates that our approach can allow anyone to communicate volumetrically, via a method for 3D videoconferencing that is not only highly accessible, but also realistic and authentic. </p>

#### 2. Look Ma, no markers: holistic performance capture without the hassle. [`arXiv`](https://arxiv.org/abs/2410.11520)

Charlie Hewitt, Fatemeh Saleh, Sadegh Aliakbarian, Lohit Petikam, Shideh Rezaeifar, Louis Florentin, <span style="color:blue"> ***Zafiirah Hosenie***</span>, Thomas J Cashman, Julien Valentin, Darren Cosker, Tadas Baltrusaitis
<p align="justify">We tackle the problem of highly-accurate, holistic performance capture for the face, body and hands simultaneously. Motion-capture technologies used in film and game production typically focus only on face, body or hand capture independently, involve complex and expensive hardware and a high degree of manual intervention from skilled operators. While machine-learning-based approaches exist to overcome these problems, they usually only support a single camera, often operate on a single part of the body, do not produce precise world-space results, and rarely generalize outside specific contexts. In this work, we introduce the first technique for marker-free, high-quality reconstruction of the complete human body, including eyes and tongue, without requiring any calibration, manual intervention or custom hardware. Our approach produces stable world-space results from arbitrary camera rigs as well as supporting varied capture environments and clothing. We achieve this through a hybrid approach that leverages machine learning models trained exclusively on synthetic data and powerful parametric models of human shape and motion. We evaluate our method on a number of body, face and hand reconstruction benchmarks and demonstrate state-of-the-art results that generalize on diverse datasets. </p>

#### 3. Hairmony: Fairness-aware hairstyle classification. [`arXiv`](https://arxiv.org/abs/2410.11528)

Givi Meishvili, James Clemoes, Charlie Hewitt, <span style="color:blue"> ***Zafiirah Hosenie***</span>, Xian Xiao, Martin de La Gorce, Tibor Takacs, Tadas Baltrusaitis, Antonio Criminisi, Chyna McRae, Nina Jablonski, Marta Wilczkowiak
<p align="justify">We present a method for prediction of a person's hairstyle from a single image. Despite growing use cases in user digitization and enrollment for virtual experiences, available methods are limited, particularly in the range of hairstyles they can capture. Human hair is extremely diverse and lacks any universally accepted description or categorization, making this a challenging task. Most current methods rely on parametric models of hair at a strand level. These approaches, while very promising, are not yet able to represent short, frizzy, coily hair and gathered hairstyles. We instead choose a classification approach which can represent the diversity of hairstyles required for a truly robust and inclusive system. Previous classification approaches have been restricted by poorly labeled data that lacks diversity, imposing constraints on the usefulness of any resulting enrollment system. We use only synthetic data to train our models. This allows for explicit control of diversity of hairstyle attributes, hair colors, facial appearance, poses, environments and other parameters. It also produces noise-free ground-truth labels. We introduce a novel hairstyle taxonomy developed in collaboration with a diverse group of domain experts which we use to balance our training data, supervise our model, and directly measure fairness. We annotate our synthetic training data and a real evaluation dataset using this taxonomy and release both to enable comparison of future hairstyle prediction approaches. We employ an architecture based on a pre-trained feature extraction network in order to improve generalization of our method to real data and predict taxonomy attributes as an auxiliary task to improve accuracy. Results show our method to be significantly more robust for challenging hairstyles than recent parametric approaches. </p>

#### 4. Investigation of a Machine learning methodology for the SKA pulsar search pipeline. [`arXiv`](https://arxiv.org/abs/2209.04430)

Shashank Sanjay Bhat, Thiagaraj Prabu, Ben Stappers, Atul Ghalame, Snehanshu Saha, T.S.B Sudarshan, <span style="color:blue"> ***Zafiirah Hosenie***</span>
<p align="justify">The SKA pulsar search pipeline will be used for real time detection of pulsars. Modern radio telescopes such as SKA will be generating petabytes of data in their full scale of operation. Hence experience-based and data-driven algorithms become indispensable for applications such as candidate detection. Here we describe our findings from testing a state of the art object detection algorithm called Mask R-CNN to detect candidate signatures in the SKA pulsar search pipeline. We have trained the Mask R-CNN model to detect candidate images. A custom annotation tool was developed to mark the regions of interest in large datasets efficiently. We have successfully demonstrated this algorithm by detecting candidate signatures on a simulation dataset. The paper presents details of this work with a highlight on the future prospects. </p>

#### 5. MeerCRAB: MeerLICHT Classification of Real and Bogus Transients using Deep Learning. [`arXiv`](https://arxiv.org/abs/2104.13950) [`Experimental Astronomy`](https://doi.org/10.1007/s10686-021-09757-1)

<span style="color:blue"> ***Zafiirah Hosenie***</span>, Steven Bloemen, Paul Groot, Robert Lyon, Bart Scheers, Benjamin Stappers, et al.
<p align="justify">Astronomers require efficient automated detection and classification pipelines when conducting large-scale surveys of the (optical) sky for variable and transient sources. Such pipelines are fundamentally important, as they permit rapid follow-up and analysis of those detections most likely to be of scientific value. We therefore present a deep learning pipeline based on the convolutional neural network architecture called ğ™¼ğšğšğš›ğ™²ğšğ™°ğ™±. It is designed to filter out the so called 'bogus' detections from true astrophysical sources in the transient detection pipeline of the MeerLICHT telescope. Optical candidates are described using a variety of 2D images and numerical features extracted from those images. The relationship between the input images and the target classes is unclear, since the ground truth is poorly defined and often the subject of debate. This makes it difficult to determine which source of information should be used to train a classification algorithm. We therefore used two methods for labelling our data (i) thresholding and (ii) latent class model approaches. We deployed variants of ğ™¼ğšğšğš›ğ™²ğšğ™°ğ™± that employed different network architectures trained using different combinations of input images and training set choices, based on classification labels provided by volunteers. The deepest network worked best with an accuracy of 99.5% and Matthews correlation coefficient (MCC) value of 0.989. The best model was integrated to the MeerLICHT transient vetting pipeline, enabling the accurate and efficient classification of detected transients that allows researchers to select the most promising candidates for their research goals. </p>

#### 6. Imbalance Learning for Variable Star Classification using Machine Learning. [`arXiv`](https://arxiv.org/abs/2002.12386) [`MNRAS`](https://doi.org/10.1093/mnras/staa642)

<span style="color:blue"> ***Zafiirah Hosenie***</span>, Robert Lyon, Benjamin Stappers, Arrykrishna Mootoovaloo, Vanessa McBride
<p align="justify">The accurate automated classification of variable stars into their respective sub-types is difficult. Machine learning based solutions often fall foul of the imbalanced learning problem, which causes poor generalisation performance in practice, especially on rare variable star sub-types. In previous work, we attempted to overcome such deficiencies via the development of a hierarchical machine learning classifier. This 'algorithm-level' approach to tackling imbalance, yielded promising results on Catalina Real-Time Survey (CRTS) data, outperforming the binary and multi-class classification schemes previously applied in this area. In this work, we attempt to further improve hierarchical classification performance by applying 'data-level' approaches to directly augment the training data so that they better describe under-represented classes. We apply and report results for three data augmentation methods in particular: Randomly Augmented Sampled Light curves from magnitude Error (ğšğ™°ğš‚ğ™»ğ™´), augmenting light curves with Gaussian Process modelling (ğ™¶ğš™ğ™µğš’ğš) and the Synthetic Minority Over-sampling Technique (ğš‚ğ™¼ğ™¾ğšƒğ™´). When combining the 'algorithm-level' (i.e. the hierarchical scheme) together with the 'data-level' approach, we further improve variable star classification accuracy by 1-4%. We found that a higher classification rate is obtained when using ğ™¶ğš™ğ™µğš’ğš in the hierarchical model. Further improvement of the metric scores requires a better standard set of correctly identified variable stars and, perhaps enhanced features are needed. </p>

#### 7. Comparing Multiclass, Binary, and Hierarchical Machine Learning Classification schemes for variable stars. [`arXiv`](https://arxiv.org/abs/1907.08189) [`MNRAS`](https://doi.org/10.1093/mnras/stz1999)

<span style="color:blue"> ***Zafiirah Hosenie***</span>, Robert Lyon, Benjamin Stappers, Arrykrishna Mootoovaloo
<p align="justify">Upcoming synoptic surveys are set to generate an unprecedented amount of data. This requires an automatic framework that can quickly and efficiently provide classification labels for several new object classification challenges. Using data describing 11 types of variable stars from the Catalina Real-Time Transient Survey (CRTS), we illustrate how to capture the most important information from computed features and describe detailed methods of how to robustly use information theory for feature selection and evaluation. We apply three machine learning algorithms and demonstrate how to optimize these classifiers via cross-validation techniques. For the CRTS data set, we find that the random forest classifier performs best in terms of balanced accuracy and geometric means. We demonstrate substantially improved classification results by converting the multiclass problem into a binary classification task, achieving a balanced-accuracy rate of âˆ¼99 per cent for the classification of Î´ Scuti and anomalous Cepheids. Additionally, we describe how classification performance can be improved via converting a â€˜flat multiclassâ€™ problem into a hierarchical taxonomy. We develop a new hierarchical structure and propose a new set of classification features, enabling the accurate identification of subtypes of Cepheids, RR Lyrae, and eclipsing binary stars in CRTS data. </p>

#### 8. DeepSource: Point Source Detection using Deep Learning. [`arXiv`](https://arxiv.org/abs/1807.02701) [`MNRAS`](https://doi.org/10.1093/mnras/stz131)

A Vafaei Sadr, Etienne E Vos, Bruce A Bassett, <span style="color:blue"> ***Zafiirah Hosenie***</span>, N Oozeer, Michelle Lochner
<p align="justify">Point source detection at low signal-to-noise ratio (SNR) is challenging for astronomical surveys, particularly in radio interferometry images where the noise is correlated. Machine learning is a promising solution, allowing the development of algorithms tailored to specific telescope arrays and science cases. We present DEEPSOURCE â€“ a deep learning solution â€“ that uses convolutional neural networks to achieve these goals. DEEPSOURCE enhances the SNR of the sources in the original map and then uses dynamic blob detection to detect sources. Trained and tested on two sets of 500 simulated 1Â° Ã— 1Â° MeerKAT images with a total of 300â€‰000 sources, DEEPSOURCE is essentially perfect in both purity and completeness down to SNR = 4 and outperforms PYBDSF in all metrics. For uniformly weighted images, it achieves a Purity Ã— Completeness (PC) score at SNR = 3 of 0.73, compared to 0.31 for the best PYBDSF model. For natural weighting, we find a smaller improvement of âˆ¼40 per cent in the PC score at SNR = 3. If instead we ask where either of the purity or completeness first drops to 90 per centâ , we find that DEEPSOURCE reaches this value at SNR = 3.6 compared to the 4.3 of PYBDSF (natural weighting). A key advantage of DEEPSOURCE is that it can learn to optimally trade off purity and completeness for any science case under consideration. Our results show that deep learning is a promising approach to point source detection in astronomical images. </p>

#### 9. No evidence for extensions to the standard cosmological model. [`arXiv`](https://arxiv.org/abs/1704.03467) [`Phys.Rev.Lett`](https://doi.org/10.1103/PhysRevLett.119.101301)

Alan Heavens, Yabebal Fantaye, Elena Sellentin, Hans Eggers, <span style="color:blue"> ***Zafiirah Hosenie***</span>, Steve Kroon, Arrykrishna Mootoovaloo

<p align="justify">We compute the Bayesian Evidence for models considered in the main analysis of Planck cosmic microwave background data. By utilising carefully-defined nearest-neighbour distances in parameter space, we reuse the Monte Carlo Markov Chains already produced for parameter inference to compute Bayes factors B for many different model-dataset combinations. Standard 6-parameter flat Î›CDM model is favoured over all other models considered, with curvature being mildly favoured only when CMB lensing is not included. Many alternative models are strongly disfavoured by the data, including primordial correlated isocurvature models (lnB=âˆ’7.8), non-zero scalar-to-tensor ratio (lnB=âˆ’4.3), running of the spectral index (lnB=âˆ’4.7), curvature (lnB=âˆ’3.6), non-standard numbers of neutrinos (lnB=âˆ’3.1), non-standard neutrino masses (lnB=âˆ’3.2), non-standard lensing potential (lnB=âˆ’4.6), evolving dark energy (lnB=âˆ’3.2), sterile neutrinos (lnB=âˆ’6.9), and extra sterile neutrinos with a non-zero scalar-to-tensor ratio (lnB=âˆ’10.8). Other models are less strongly disfavoured with respect to flat Î›CDM. As with all analyses based on Bayesian Evidence, the final numbers depend on the widths of the parameter priors. We adopt the priors used in the Planck analysis, while performing a prior sensitivity analysis. Our quantitative conclusion is that extensions beyond the standard cosmological model are disfavoured by Planck data. Only when newer Hubble constant measurements are included does Î›CDM become disfavoured, and only mildly, compared with a dynamical dark energy model (lnBâˆ¼+2). </p>

#### 10. Marginal Likelihoods from Monte Carlo Markov Chains. [`arXiv`](https://arxiv.org/abs/1704.03472)

Alan Heavens, Yabebal Fantaye, Arrykrishna Mootoovaloo, Hans Eggers, <span style="color:blue"> ***Zafiirah Hosenie***</span>, Steve Kroon, Elena Sellentin

<p align="justify">In this paper, we present a method for computing the marginal likelihood, also known as the model likelihood or Bayesian evidence, from Markov Chain Monte Carlo (MCMC), or other sampled posterior distributions. In order to do this, one needs to be able to estimate the density of points in parameter space, and this can be challenging in high numbers of dimensions. Here we present a Bayesian analysis, where we obtain the posterior for the marginal likelihood, using kth nearest-neighbour distances in parameter space, using the Mahalanobis distance metric, under the assumption that the points in the chain (thinned if required) are independent. We generalise the algorithm to apply to importance-sampled chains, where each point is assigned a weight. We illustrate this with an idealised posterior of known form with an analytic marginal likelihood, and show that for chains of length âˆ¼10^5 points, the technique is effective for parameter spaces with up to âˆ¼20 dimensions. We also argue that k=1 is the optimal choice, and discuss failure modes for the algorithm. In a companion paper (Heavens et al. 2017) we apply the technique to the main MCMC chains from the 2015 Planck analysis of cosmic background radiation data, to infer that quantitatively the simplest 6-parameter flat Î›CDM standard model of cosmology is preferred over all extensions considered. </p>



